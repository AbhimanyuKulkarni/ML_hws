{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "vocabulary = ['a','b','c','d','e','f','g','h','i','j','k',\n",
    "             'l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
    "language = ['e','s','j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name, path = './languageID/'):\n",
    "    f = open(path+file_name, 'r')\n",
    "    content = f.read()\n",
    "    content = content.replace('\\n', '')\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boc(file):\n",
    "    \"\"\"\n",
    "    get bag of character for input file\n",
    "    \"\"\"\n",
    "    l = len(file)\n",
    "    vocb = dict()\n",
    "    for i in range(l):\n",
    "        if file[i] in vocb:\n",
    "            vocb[file[i]] += 1\n",
    "        else:\n",
    "            vocb[file[i]] = 1\n",
    "    return vocb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(file):\n",
    "    \"\"\"\n",
    "    use counts of characters as embedding\n",
    "    emb: embedding array of size of 27(a-z and ' ')\n",
    "    \"\"\"\n",
    "    vocb = get_boc(file)\n",
    "    emb = []\n",
    "    for v in vocabulary:\n",
    "        if v not in vocb:\n",
    "            emb.append(0)\n",
    "        else:\n",
    "            emb.append(vocb[v])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f76d1eb2662c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_boc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "print(get_boc(f))\n",
    "print(get_embedding(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_training = []\n",
    "s_training = []\n",
    "j_training = []\n",
    "for i in range(10):\n",
    "    e_training.append(read_file(\"e\"+str(i)+'.txt'))\n",
    "    s_training.append(read_file(\"s\"+str(i)+'.txt'))\n",
    "    j_training.append(read_file(\"j\"+str(i)+'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = {'e':e_training,'s':s_training,'j':j_training}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "p_prior = (10+1)/(30+3)\n",
    "log_prior = math.log(p_prior)\n",
    "\n",
    "print(p_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.2 & 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_theta = {'e':[0]*27,'s':[0]*27,'j':[0]*27}\n",
    "for l in language:\n",
    "    for f in training[l]:\n",
    "        tmp_emb = get_embedding(f)\n",
    "        raw_theta[l] = [raw_theta[l][i] + tmp_emb[i] for i in range(27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[910, 168, 325, 332, 1594, 286, 264, 714, 838, 21, 56, 438, 310, 876, 975, 253, 8, 814, 1001, 1212, 403, 140, 234, 17, 209, 9, 2712]\n"
     ]
    }
   ],
   "source": [
    "print(raw_theta['e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using log here to avoid underflow\n",
    "log_theta = {'e':[0]*27,'s':[0]*27,'j':[0]*27}\n",
    "for l in language:\n",
    "    total = sum(raw_theta[l])\n",
    "    # using add-1 smoothing\n",
    "    log_theta[l] = [math.log((raw_theta[l][i]+1))-math.log((total+len(vocabulary))) for i in range(27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_e: [0.0601478938333553, 0.011158061534398517, 0.02152383467582199, 0.021986002905057433, 0.10530833223293272, 0.018948897398653106, 0.017496368678198853, 0.04720718341476294, 0.05539416347550504, 0.0014525287204542451, 0.003763369866631453, 0.028984550376336977, 0.020533474184603183, 0.05790307671992602, 0.0644394559619701, 0.016770104317971733, 0.0005942162947312824, 0.053809586689554975, 0.06615608081341603, 0.08008715172322722, 0.026673709230159777, 0.009309388617456752, 0.01551564769576125, 0.0011884325894625637, 0.013865046877063242, 0.0006602403274792024, 0.17912320084510747]\n",
      "0.9999999999999994\n",
      "theta_s: [0.1045042824573295, 0.008256824203586173, 0.037525417462567025, 0.03974366874114241, 0.11374699611806025, 0.008626532750015403, 0.007209316655370021, 0.00455973873929386, 0.04984903567687472, 0.0066547538357261725, 0.0003080904553576929, 0.05292994023045165, 0.025817980158974674, 0.05416230205188243, 0.07246287510012941, 0.024277527882186217, 0.007702261383942331, 0.05927660361082015, 0.06574650317333171, 0.03561525663934933, 0.033705095816131625, 0.005915336742867707, 0.0001232361821430773, 0.002526341733933084, 0.007887115657156942, 0.0027111960071477003, 0.16815577053422892]\n",
      "1.0\n",
      "theta_j: [0.13167632479229205, 0.010891572994484391, 0.0055156042728478644, 0.01724499057460029, 0.0601829225720868, 0.0039097954339174755, 0.014033372896739503, 0.031767087900579465, 0.09697689031627449, 0.0023738043705927524, 0.05739021154786003, 0.001466173287719052, 0.03979613209523144, 0.056692033791803355, 0.0911121971653983, 0.0009076310828736989, 0.0001396355512113384, 0.042798296446275204, 0.042169936465824176, 0.05697130489422603, 0.07058577113733153, 0.0002792711024226768, 0.019758430496404376, 6.981777560566918e-05, 0.014173008447950839, 0.007749773092229276, 0.12336800949521742]\n",
      "0.9999999999999994\n"
     ]
    }
   ],
   "source": [
    "for l in log_theta:\n",
    "#     print(log_theta[l])\n",
    "    print(\"theta_\"+l+\":\", [math.e**log_theta[l][i] for i in range(27)])\n",
    "    print(sum([math.e**log_theta[l][i] for i in range(27)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_file('e10.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = get_embedding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164, 32, 53, 57, 311, 55, 51, 140, 140, 3, 6, 85, 64, 139, 182, 53, 3, 141, 186, 225, 65, 31, 47, 4, 38, 2, 498]\n"
     ]
    }
   ],
   "source": [
    "print(test_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:  -7841.786386770362\n",
      "s:  -8452.383194656028\n",
      "j:  -8759.518886307718\n"
     ]
    }
   ],
   "source": [
    "log_p = {'e':0,'s':0,'j':0}\n",
    "for l in language:\n",
    "    tmp_log_theta = [log_theta[l][i]*test_emb[i] for i in range(27)]\n",
    "    log_p[l] = sum(tmp_log_theta)\n",
    "    print(l+\": \", log_p[l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_test = []\n",
    "s_test = []\n",
    "j_test = []\n",
    "for i in range(10,20):\n",
    "    e_test.append(read_file(\"e\"+str(i)+'.txt'))\n",
    "    s_test.append(read_file(\"s\"+str(i)+'.txt'))\n",
    "    j_test.append(read_file(\"j\"+str(i)+'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'e':e_test,'s':s_test,'j':j_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_theta(training,dim):\n",
    "    \"\"\"\n",
    "    training process of this naive bayes model\n",
    "    \n",
    "    training: training set of a single class y\n",
    "    dim: feature dimension\n",
    "    return log(theta_i) for i in [1,d]\n",
    "    \n",
    "    using log() to avoid underflow\n",
    "    \"\"\"\n",
    "    raw_theta = [0]*dim\n",
    "    log_theta = [0]*dim\n",
    "    for f in training:\n",
    "        tmp_emb = get_embedding(f)\n",
    "        raw_theta = [raw_theta[i] + tmp_emb[i] for i in range(27)]        \n",
    "    total = sum(raw_theta)\n",
    "    # using add-1 smoothing\n",
    "    log_theta = [math.log((raw_theta[i]+1))-math.log((total+len(vocabulary))) for i in range(27)]\n",
    "    return log_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "[-2.8109488524138104, -4.495593034750695, -3.838594368307061, -3.8173492596933247, -2.2508627344548238, -3.9660095339141472, -4.045761923687547, -3.053209206979761, -2.8932810432065628, -6.534449296315453, -5.582440481839218, -3.540992336598597, -3.8856988374945347, -2.8489847573015856, -2.7420291632606766, -4.088157482655232, -7.428267172337549, -2.922303636432906, -2.7157384680289587, -2.5246398407297184, -3.624076871712618, -4.6767318592956, -4.16590623552961, -6.735119991777604, -4.2783842189563, -7.322906656679723, -1.7196814370148372]\n",
      "s\n",
      "[-2.2585272279640334, -4.796715244364971, -3.2827367766059847, -3.2253047275201094, -2.1737786292530847, -4.752912621706578, -4.932381109518126, -5.390489951111712, -2.9987561272573906, -5.012423817191662, -8.085117131881782, -2.938786122331627, -3.6566841243937445, -2.915770146630705, -2.6246809158573097, -3.718204135017948, -4.86624130701358, -2.8255405936501754, -2.7219487930141284, -3.334981175643504, -3.3901062418939008, -5.130206852848046, -9.001407863755936, -5.980982977611574, -4.842524780396265, -5.91036541039762, -1.782864523607543]\n",
      "j\n",
      "[-2.027408452586463, -4.519765908530329, -5.200174063312844, -4.060233579151888, -2.810366645116173, -5.544270225044716, -4.26631700772079, -3.4493244968289156, -2.3332825730255218, -6.043261391163704, -2.8578815207236863, -6.525099478056443, -3.2239855549512697, -2.870121575618188, -2.3956635960230717, -7.00467255831833, -8.87647473521992, -3.1512569798436543, -3.166047717845051, -2.865207560815759, -2.6509266967593943, -8.183327554659975, -3.924175018136628, -9.569621915779866, -4.256415936738079, -4.860091714467532, -2.0925834434601693]\n"
     ]
    }
   ],
   "source": [
    "log_theta = dict()\n",
    "for l in language:\n",
    "    log_theta[l] = get_log_theta(training[l],27)\n",
    "    print(l)\n",
    "    print(log_theta[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_emb, log_theta, log_prior_p):\n",
    "    \"\"\"\n",
    "    test_emb: test file's embedding\n",
    "    log_theta & prior: dict of classes Y\n",
    "    \"\"\"\n",
    "    highest_log_p = float(\"-inf\")\n",
    "    prediction = None\n",
    "    for y in log_theta.keys():\n",
    "        tmp_log_theta = [log_theta[y][i]*test_emb[i] for i in range(27)]\n",
    "        log_p[y] = sum(tmp_log_theta)+log_prior_p[y]\n",
    "        if log_p[y] > highest_log_p:\n",
    "            highest_log_p = log_p[y]\n",
    "            prediction = y\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164, 32, 53, 57, 311, 55, 51, 140, 140, 3, 6, 85, 64, 139, 182, 53, 3, 141, 186, 225, 65, 31, 47, 4, 38, 2, 498]\n",
      "[199, 47, 70, 86, 352, 78, 47, 143, 170, 1, 15, 124, 59, 191, 236, 38, 3, 147, 194, 272, 86, 35, 57, 2, 43, 2, 618]\n",
      "[122, 23, 59, 36, 196, 35, 15, 89, 103, 0, 8, 48, 38, 106, 111, 25, 1, 87, 124, 194, 58, 15, 24, 3, 25, 0, 348]\n",
      "[97, 24, 25, 32, 173, 38, 23, 85, 87, 0, 7, 45, 42, 90, 127, 22, 2, 79, 94, 179, 49, 8, 29, 2, 28, 1, 299]\n",
      "[113, 24, 33, 32, 164, 38, 33, 87, 87, 2, 5, 57, 45, 90, 104, 23, 1, 72, 109, 140, 36, 9, 23, 1, 19, 1, 322]\n",
      "[108, 19, 34, 42, 157, 31, 29, 67, 101, 0, 8, 42, 49, 91, 100, 27, 2, 84, 96, 149, 38, 16, 29, 0, 23, 1, 271]\n",
      "[159, 36, 66, 60, 316, 45, 35, 138, 138, 0, 14, 97, 53, 164, 168, 53, 0, 146, 169, 219, 56, 27, 46, 7, 32, 0, 477]\n",
      "[155, 26, 62, 53, 267, 58, 41, 110, 128, 3, 14, 65, 63, 149, 174, 45, 3, 107, 145, 200, 55, 22, 30, 2, 30, 1, 416]\n",
      "[126, 16, 31, 37, 166, 32, 21, 57, 98, 0, 7, 57, 43, 100, 90, 29, 0, 84, 105, 118, 46, 15, 24, 3, 23, 1, 302]\n",
      "[31, 8, 14, 17, 59, 12, 8, 20, 49, 0, 1, 10, 19, 39, 39, 13, 1, 30, 37, 44, 17, 7, 5, 1, 4, 0, 97]\n"
     ]
    }
   ],
   "source": [
    "log_prior_p = {'e':math.log(1/3),'s':math.log(1/3),'j':math.log(1/3)}\n",
    "e_prediction = []\n",
    "for f in test['e']:\n",
    "    test_emb = get_embedding(f)\n",
    "    print(test_emb)\n",
    "    e_prediction.append(predict(test_emb, log_theta, log_prior_p))\n",
    "s_prediction = []\n",
    "for f in test['s']:\n",
    "    test_emb = get_embedding(f)\n",
    "    s_prediction.append(predict(test_emb, log_theta, log_prior_p))\n",
    "j_prediction = []\n",
    "for f in test['j']:\n",
    "    test_emb = get_embedding(f)\n",
    "    j_prediction.append(predict(test_emb, log_theta, log_prior_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e']\n",
      "['s', 's', 's', 's', 's', 's', 's', 's', 's', 's']\n",
      "['j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(e_prediction)\n",
    "print(s_prediction)\n",
    "print(j_prediction)\n",
    "print(len(e_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2019)\n",
    "class_num = random.randint(0,3)\n",
    "num = random.randint(10,19)\n",
    "file_name = language[class_num]+str(num)+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = read_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la hinchazon o edema las ojeras las bolsas y las arrugas son los males que se instalan alrededor de los ojosla prudencia es imprescindible a la hora de afrontar la depilacion unas cejas excesivamente depiladas tardan mucho tiempo en recuperar su forma inicial crecen con menos densidad e incluso puede aparecer calvasesta zona tan fragil ademas de estar expuesta a las agresiones del sol el frio el viento la humedad  la contaminacion y el aire acondicionado tambien se ve afectada por la falta se sueno el estres el tabaco el alcohol y acumulacion de horas frente al ordenadorno existe mirada perfecta sin unas cejas cuidadas con mimo las cejas enmarcan la mirada son fundamentales en la expresion del rostro y  requieren un cuidado pequeno aunque constanteprovocadas por venas bajo la piel las ojeras resultan muy antiesteticas el te la manzanilla el aloe vera y la calendula son algunos remedios naturales aunque en casos graves se puede acudir a la cirugia estetica'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_test_set = list(test_set)\n",
    "random.shuffle(shuffle_test_set)\n",
    "shuffle_test_set = ''.join(shuffle_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aenml ecsmlt lote iao j ltf c naelurnunuaoir    em uc r ee rlaeebar nn d aleeedlo sm me  lglarsi l aiceopod rroons aolioss eeiounmlhtma oao oiraoa dr  ceas  ustroore t ednuasetal  d ecads acs d subicdl d tsmuliq  vicaoompaeo aeeo desaledpeeoemta i uihpslala tocloumca scsld oalnecner ad cdeacotxa upldu tetea eaaao eut connente ecaerssanrs  elamdeanse lolsofe  pcalunaaaaol u oni neonann jevarsife ayeecyldrarlcs liouo p y ernlilio s etsean   caesaosnchc narvsadvcu aabssnla i uneh naes   e  oertgqaltarpuirr rueeorleuh   iaaai  rsilniniaibedoe rld usdejarvsaxs o ajiaeddseal sn eoai lt ecmerfadonsn esnnesac izrcup aeennuv se aamdaszvoulaaapialadust aeese oaanclsaar oear   mesjdrsnsnpcipeaaor iei pjlsem  o taan asaadlc malaaqlmid eqye eopngatlaerfdnlcf  rlnetnaaertsldlmtn entfaso msnciirnxninh iirnes ehianueuuoncalssczua   east sas garoogi ecnero  afaee er qad eeieaoa   aei pesdpra asaaj  cvmbnls xuc oaterft rtl  sg iu dplrsyssdeldlnae e an  ondacyoamrini c  dte'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122, 5, 39, 39, 107, 9, 6, 7, 45, 7, 0, 58, 22, 61, 58, 17, 5, 48, 67, 31, 33, 8, 0, 4, 6, 3, 162] [122, 5, 39, 39, 107, 9, 6, 7, 45, 7, 0, 58, 22, 61, 58, 17, 5, 48, 67, 31, 33, 8, 0, 4, 6, 3, 162]\n"
     ]
    }
   ],
   "source": [
    "test_emb = get_embedding(test_set)\n",
    "shuffle_emb = get_embedding(shuffle_test_set)\n",
    "print(test_emb,shuffle_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(test_emb, log_theta, log_prior_p)\n",
    "shuffle_pred = predict(shuffle_emb,log_theta,log_prior_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s s\n"
     ]
    }
   ],
   "source": [
    "print(pred,shuffle_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2Wekatxt(file):\n",
    "    \"\"\"\n",
    "    Assuem the input file only has ' ' and a-z\n",
    "    \"\"\"\n",
    "    c_list = []\n",
    "    for i in range(len(file)):\n",
    "        if file[i] != ' ':\n",
    "            c_list.append(file[i])\n",
    "            c_list.append(' ')\n",
    "        else:\n",
    "            c_list.append('space')\n",
    "            c_list.append(' ')\n",
    "    return ''.join(c_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in language:\n",
    "    for i in range(20):\n",
    "        tmp = read_file(l+str(i)+'.txt')\n",
    "        out = txt2Wekatxt(tmp)\n",
    "        f = open(\"./Weka text/\"+l+\"/\"+l+str(i)+'.txt', 'w')\n",
    "        f.write(out)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the best explanation that we have today of this continuous accretion of energy is that it is due to shrinkage of the suns bulk under the force of gravity gravity is one of the most mysterious forces of nature but it is an obvious fact that bodies behave as if they attracted one another and newton worked out the law of this attraction we may say without trying to go too deeply into things that every particle of matter attracts every other throughout the universe if the diameter of the sun were to shrink by one mile all round this would mean that all the millions of tons in thepg  outer onemile thickness would have a straight drop of one mile towards the centre and that is not all because obviously the layers below this outer mile would also drop inwards each to a less degree than the one above it what a tremendous movement of matter however slowly it might take place and what a tremendous energy would be involved astronomers calculate that the above shrinkage of one mile all round would require fifty years for its completion assuming reasonably that there is close and continuous relationship between loss of heat by radiation and shrinkage even if this were true we need not feel overanxious on this theory before the sun became too cold to support life many millions of years would be requirednos  and  show the effect of the planets rotation nos  and  depict quite different sections note the change in the polar snowcaps in the last twosaturn is a beautiful object in the telescope because it has ten moons to include one which is disputed and a wonderful system of rings round it the socalled rings are a mighty swarm of meteoritespieces of iron and stone of all sorts and sizes which reflect the light of the sun to us this ocean of matter is some miles deep and stretches from a few thousand miles from the surface of the planet to  miles out in space some astronomers think that this is volcanic material which has been shot out of the planet others regard it as stuff which would have combined to form an eleventh moon but was prevented by the nearness of saturn itself there is no evidence of life on saturnbut there are many things that point to absence of air on the moon even the photographs we reproduce tell the same story the edges of the shadows are all hard and black if there had been an appreciable atmosphere it would have scattered the suns light on to the edges and produced a gradual shading off such as we see on the earth this relative absence of air must give rise to some surprising effects there will be no sounds on the moon because sounds are merely air waves even a meteor shattering itself to a violent end against the surface of the moon would make no noise nor would it herald its coming by glowing into a shooting star as it would on entering the earths atmosphere there will be no floating dust no scent no twilight no blue sky no twinkling of the stars the sky will be always black and the stars will be clearly visible by day as by night the suns wonderful corona which no man on earth even by seizing every opportunity during eclipses can hope to see for more than two hours in all in a long lifetime will be visible all day so will the great red flames of the sun of course there will be no life and no landscape effects and scenery effects due to vegetation\n"
     ]
    }
   ],
   "source": [
    "print(test['e'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
