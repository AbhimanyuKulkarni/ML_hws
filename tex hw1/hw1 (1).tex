\documentclass[a4paper]{article}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{paralist}
\usepackage{epstopdf}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{multicol}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyvrb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{float}
\usepackage{paralist}
\usepackage[svgname]{xcolor}
\usepackage{enumerate}
\usepackage{array}
\usepackage{times}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage{comment}
\usepackage{environ}
\usepackage{times}
\usepackage{textcomp}
\usepackage{caption}


\urlstyle{rm}

\setlength\parindent{0pt} % Removes all indentation from paragraphs
\theoremstyle{definition}
\newtheorem{definition}{Definition}[]
\newtheorem{conjecture}{Conjecture}[]
\newtheorem{example}{Example}[]
\newtheorem{theorem}{Theorem}[]
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}

\floatname{algorithm}{Procedure}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\norm}[1]{\lVert#1\rVert}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\Nat}{\mathbb{N}}
\newcommand{\br}[1]{\{#1\}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\renewcommand{\qedsymbol}{$\blacksquare$}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}

\newcommand{\vc}[1]{\boldsymbol{#1}}
\newcommand{\xv}{\vc{x}}
\newcommand{\Sigmav}{\vc{\Sigma}}
\newcommand{\alphav}{\vc{\alpha}}
\newcommand{\muv}{\vc{\mu}}

\newcommand{\red}[1]{\textcolor{red}{#1}}

\def\x{\mathbf x}
\def\y{\mathbf y}
\def\w{\mathbf w}
\def\v{\mathbf v}
\def\E{\mathbb E}
\def\V{\mathbb V}

% TO SHOW SOLUTIONS, include following (else comment out):
\newenvironment{soln}{
    \leavevmode\color{blue}\ignorespaces
}{}


\hypersetup{
%    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\geometry{
  top=1in,            % <-- you want to adjust this
  inner=1in,
  outer=1in,
  bottom=1in,
  headheight=3em,       % <-- and this
  headsep=2em,          % <-- and this
  footskip=3em,
}


\pagestyle{fancyplain}
\lhead{\fancyplain{}{Homework 1}}
\rhead{\fancyplain{}{CS 760 Machine Learning}}
\cfoot{\thepage}

\title{\textsc{Homework 1}} % Title

%%% NOTE:  Replace 'NAME HERE' etc., and delete any "\red{}" wrappers (so it won't show up as red)

\author{
\red{$>>$Sean(Xiaoyu) Sun$<<$} \\
\red{$>>$9078202463$<<$}\\
} 

\date{}

\begin{document}

\maketitle 


\textbf{Instructions:} 
This is a background self-test on the type of math we will encounter in class. If you find many questions intimidating, we suggest you drop 760 and take it again in the future when you are more prepared.

Use this latex file as a template to develop your homework.
Submit your homework on time as a single pdf file to Canvas.
There is no need to submit the latex source or any code.
Please check Piazza for updates about the homework.


\section{Logistics [5 pts]}
Read the course webpage at \url{http://pages.cs.wisc.edu/~jerryzhu/cs760.html} and answer the following questions:
\begin{enumerate}
\item Where do we post announcements and clarifications?

\begin{soln}  The instructors and TAs will post announcements, clarifications on Piazza. And also http://pages.cs.wisc.edu/~jerryzhu/cs760.html \end{soln}

\item What time of day (hour:minute) are all homeworks due?

\begin{soln} Homework is always due the minute before class starts on the due date.\end{soln}

\item Will late homework be accepted?

\begin{soln} NO \end{soln}

\item Tom received the following scores on his 7 homeworks: 0, 59, 92, 95, 98, 100, 100.  According to the homework policies, what is Tom's final average homework score?

\begin{soln} The lowest score will be dropped. So it will be (59+92+95+98+100+100)/6 = 90.667 \end{soln}

\item How can you discuss homework questions with fellow students while avoiding the impression of cheating?

\begin{soln} Declare it in the solution \end{soln}
\end{enumerate}

\section{Vectors and Matrices [2 pts]}
Consider the matrix $X$ and the vectors $\mathbf{y}$ and $\textbf{z}$ below:
$$
X = \begin{pmatrix}
6 & 7 \\ 8 & 9 \\
\end{pmatrix}
\qquad \mathbf{y} = \begin{pmatrix}
2 \\ 3
\end{pmatrix} \qquad \mathbf{z} = \begin{pmatrix}
7 \\ 6
\end{pmatrix}
$$
\begin{enumerate}
	\item 	Computer $\mathbf{y}^\top X \mathbf{z}$\\
	    \begin{soln} 498 \end{soln}
	\item 	Is $X$ invertible? If so, give the inverse, and if no, explain why not.\\
        \begin{soln}  It is veritble because its determinant is non-zero. $X^{-1} =  \begin{pmatrix} -4.5 & 3.5 \\ 4 & -3 \\\end{pmatrix} $\end{soln}
\end{enumerate}


\section{Calculus [1 pts]}
\begin{enumerate}
	\item If $y = e^x + \tan(z)x^{6z} - \ln(\frac{7x + z}{x^{4}})$, what is the partial derivative of $y$ with respect to $x$?\\
	\begin{soln}  $e^x+6z{tan(z)}{x^{6z-1}}+\frac{21x+4z}{7x^2+zx} $\end{soln}
\end{enumerate}




\section{Probability and Statistics [4 pts]}
Consider a sequence of data $S = (0, 1, 1, 0, 1, 1, 1)$ created by flipping a coin $x$ seven times, where 0 denotes that the coin turned up heads and 1 denotes that it turned up tails.
\begin{enumerate}
	\item 	What is the probability of observing this data, assuming it was generated by flipping a biased coin with $p(x=1) = 0.7$?
	    \begin{soln} \\$0.7^5*0.3^2 = 0.015$ \end{soln}
	\item 	Note that the probability of this data sample could be greater if the value of $p(x = 1)$ was not $0.7$, but instead some other value. What is the value that maximizes the probability of $S$? Please justify your answer.\\
	    \begin{soln} $ f(p)=p^5(1-p)^2 \\ f'(p) = p^5+p^7-2p^6\\$ given p is in the range of (0,1), when p = 5/7, f'(p)=0, which means f(p) reaches the maximum. \end{soln}
	\item 	Consider the following joint probability table where both $A$ and $B$ are binary random variables: 
\begin{table}[htb]
\centering
	\begin{tabular}{ccc}\hline
	A & B & $P(A, B)$  \\\hline
	0 & 0 & 0.4 \\
	0 & 1 & 0.3 \\
	1 & 0 & 0.2 \\
	1 & 1 & 0.1 \\\hline
	\end{tabular}
\end{table}
\begin{enumerate}
	\item 	What is $P(A = 0 | B = 1)$?\\
	    \begin{soln}   $P(A = 0 | B = 1) = \frac{0.3}{0.3+0.1} = \frac{3}{4}$\end{soln}
	\item 	What is $P(A = 0 \vee B = 0 )$?\\
	    \begin{soln}  $P(A = 0 \vee B = 0 ) = 1-0.1=0.9$ \end{soln}
\end{enumerate}
\end{enumerate}


\section{Big-O Notation [3 pts]}
For each pair $(f, g)$ of functions below, list which of the following
are true: $f(n) = O(g(n))$, $g(n) = O(f(n))$, both, or
neither. Briefly justify your answers.
\begin{enumerate}
	\item 	$f(n) = \frac{n}{2}$, $g(n) = \log_{2}(n)$.\\
	    \begin{soln}  $g(n) = O(f(n))$\\beacue when $ n>2, |g(n)|<|f(n)|$ \end{soln}
	\item 	$f(n) = \ln(n)$, $g(n) = \log_{2}(n)$.\\
	    \begin{soln}  $f(n) = O(g(n))$\\beacue when $n>1, |f(n)|<|g(n)|$ \end{soln}
	\item 	$f(n) = n^{100}$, $g(n) = 100^n$.\\
	    \begin{soln}  $f(n) = O(g(n))$\\beacue there is an N that when $n>N, |f(n)|<|g(n)|$ \end{soln}
\end{enumerate}





\section{Probability and Random Variables }
\subsection{Probability [5 pts]}
State true or false. Here $\Omega$ denotes the sample space and $A^c$ denotes the complement of the event $A$.
\begin{enumerate}
\item For any $A, B \subseteq \Omega$, $P(A|B)P(B) = P(B|A)P(A)$.\\
  \begin{soln}  True \end{soln}
\item For any $A, B \subseteq \Omega$, $P(A \cup B) = P(A) + P(B) - P(A | B)$.\\         
  \begin{soln}  False. It should be $P(A \cup B) = P(A) + P(B) - P(AB)$.  \end{soln}
\item For any $A, B, C \subseteq \Omega$ such that $P(B \cup C) > 0$,
  $\frac{P(A \cup B \cup C)}{P(B \cup C)} \geq P(A | B \cup C) P(B \cup C)$.\\ \begin{soln}  True\end{soln}
\item For any $A, B\subseteq\Omega$ such that $P(B) > 0, P(A^c) > 0$,
  $P(B|A^C) + P(B|A) = 1$.\\ 
  \begin{soln}  False. \end{soln}
\item For any $n$ events $\{A_i\}_{i=1}^n$, if
  $P(\bigcap_{i=1}^n A_i) = \sum_{i=1}^n P(A_i)$, then
  $\{A_i\}_{i=1}^n$ are mutually independent.\\
  \begin{soln}  False \end{soln}
\end{enumerate}

\subsection{Discrete and Continuous Distributions [5 pts]}
Match the distribution name to its probability density / mass
function. Below, $|\xv| = k$.
\begin{enumerate}[(a)]
\begin{minipage}{0.3\linewidth}
    \item Laplace \begin{soln}  H. \end{soln}
    \item Multinomial \begin{soln} G I\end{soln}
    \item Poisson \begin{soln}  L  \end{soln} 
    \item Dirichlet \begin{soln}  K \end{soln}
    \item Gamma \begin{soln}  J\end{soln}
\end{minipage}
\begin{minipage}{0.5\linewidth}
    \item $f(\xv; \Sigmav, \muv) = \frac{1}{\sqrt{(2\pi)^k \mathrm{det}(\Sigmav) }} \exp\left( -\frac{1}{2}
        (\xv - \muv)^T \Sigmav^{-1} (\xv - \muv)  \right)$
    \item $f(x; n, \alpha) = \binom{n}{x} \alpha^x (1 - \alpha)^{n-x}$
      for $x \in \{0,\ldots, n\}$; $0$ otherwise
    \item $f(x; b, \mu) = \frac{1}{2b} \exp\left( - \frac{|x - \mu|}{b} \right)$
    \item $f(\xv; n, \alphav) = \frac{n!}{\Pi_{i=1}^k x_i!}
      \Pi_{i=1}^k \alpha_i^{x_i}$ for $x_i \in \{0,\ldots,n\}$ and
      $\sum_{i=1}^k x_i = n$; $0$ otherwise
    \item $f(x; \alpha, \beta) = \frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{\alpha -
        1}e^{-\beta x}$ for $x \in (0,+\infty)$; $0$ otherwise
    \item $f(\xv; \alphav) = \frac{\Gamma(\sum_{i=1}^k
        \alpha_i)}{\prod_{i=1}^k \Gamma(\alpha_i)} \prod_{i=1}^{k}
      x_i^{\alpha_i - 1}$ for $x_i \in (0,1)$ and $\sum_{i=1}^k x_i =
      1$; 0 otherwise
    \item $f(x; \lambda) = \lambda^x \frac{e^{-\lambda}}{x!}$ for all
      $x \in Z^+$; $0$ otherwise
\end{minipage}
\end{enumerate}
        
\subsection{Mean and Variance [5 pts]}
\begin{enumerate}
\item Consider a random variable which follows a Binomial
  distribution: $X \sim \text{Binomial}(n, p)$.
  \begin{enumerate}
  \item What is the mean of the random variable?\\
    \begin{soln}  np \end{soln}
  \item What is the variance of the random variable?\\
    \begin{soln} np(1-p) \end{soln}
  \end{enumerate}

\item Let $X$ be a random variable and
  $\mathbb{E}[X] = 1, \Var(X) = 1$. Compute the following values:
  \begin{enumerate}
  \item $\mathbb{E}[3X]$\\
    \begin{soln}  3. \end{soln}
  \item $\Var(3X)$\\
    \begin{soln}  9 \end{soln}
  \item $\Var(X+3)$\\
    \begin{soln}  3 \end{soln}
  \end{enumerate}
\end{enumerate}

%\clearpage

\subsection{Mutual and Conditional Independence [4 pts]}
\begin{enumerate}
\item If $X$ and $Y$ are independent random variables, show that
  $\mathbb{E}[XY] = \mathbb{E}[X]\mathbb{E}[Y]$.
  
  \begin{soln}  $\mathbb{E}[XY] = {P(XY)}{X}{Y}$ \\ since X and Y are independent, so $P(XY) = P(X)P(Y)$\\ so $\mathbb{E}[XY] = {P(X)X}{P(Y)Y} = \mathbb{E}[X]\mathbb{E}[Y]$ \end{soln}
  
\item If $X$ and $Y$ are independent random variables, show that
  $\Var(X+Y) = \Var(X) + \Var(Y)$. \\
  Hint: $\Var(X+Y) = \Var(X) + 2\Cov(X, Y) + \Var(Y)$
  
  \begin{soln}  since $\Cov(X, Y) = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y] = 0$ \\ so $\Var(X+Y) = \Var(X) + \Var(Y)$ \end{soln}
 
\item If we roll two dice that behave independently of each
  other, will the result of the first die tell us something about the
  result of the second die? 
  
  \begin{soln}  If they are same dice, the variance and mean value of the first die should be consistent with the second one. \end{soln}
  
  If, however, the first die's result is a 1,
  and someone tells you about a third event --- that the sum of the two
  results is even --- then given this information is the result of the second die
  independent of the first die? 
  
  \begin{soln}  No \end{soln}
\end{enumerate}

\subsection{Central Limit Theorem [1 pts]}
Provide one line explanation.
\begin{enumerate}
\item Let $X_i\sim\mathcal{N}(0, 1)$ and $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$, then the distribution of $\bar{X}$ satisfies 
  $$\sqrt{n}\bar{X}\overset{n\rightarrow\infty}{\longrightarrow}\mathcal{N}(0, 1)$$
  \begin{soln}  According to CLT, when enough observations is made, the average will be closely approximated by a normal distribution. \end{soln}
  
\end{enumerate}



\section{Linear algebra}


\subsection{Norms [3 pts]}
Draw the regions corresponding to vectors $\mathbf{x}\in\RR^2$ with the following norms:
\begin{enumerate}
	\item 	$||\mathbf{x}||_1\leq 1$ (Recall that $||\mathbf{x}||_1 = \sum_i |x_i|$)
	\begin{soln}
	    \begin{figure}[H]
	        \centering
	        \includegraphics[width=0.4\textwidth]{2.pdf}
	        \captionsetup{labelformat=empty}
	        \caption{}
	        \label{fig:my_label}
	    \end{figure}
	\end{soln}
	\item 	$||\mathbf{x}||_2 \leq 1$ (Recall that $||\mathbf{x}||_2 =\sqrt{\sum_i x_i^2}$)
	\begin{soln}
	    \begin{figure}[H]
	        \centering
	        \includegraphics[width=0.4\textwidth]{1.pdf}
	        \captionsetup{labelformat=empty}
	        \caption{}
	        \label{fig:my_label}
	    \end{figure}
	\end{soln}
	\item 	$||\mathbf{x}||_\infty \leq 1$ (Recall that $||\mathbf{x}||_\infty = \max_i |x_i|$)         
	\begin{soln}
	    \begin{figure}[H]
	        \centering
	        \includegraphics[width=0.4\textwidth]{333.png}
	        \captionsetup{labelformat=empty}
	        \caption{}
	        \label{fig:my_label}
	    \end{figure}
	\end{soln}

\end{enumerate}




\subsection{Geometry [2 pts]}
Prove the following.  Provide all steps.
\begin{enumerate}
\item 	The smallest Euclidean distance from the origin to some point $\mathbf{x}$ in the hyperplane $\mathbf{w}^\top\mathbf{x} + b = 0$ is $\frac{|b|}{||\mathbf{w}||_2}$.  You may assume $\mathbf{w} \neq 0$.\\
\begin{soln}  The smallest Euclidean distance from a point $P$ to a hyper plane is $\frac{|\mathbf{w}^\top\mathbf{P} + b|}{\sqrt{|w|^2}}$ \\ so, when P is the orgin, the distance is $\frac{|b|}{||\mathbf{w}||_2}$. \end{soln}

\item 	The Euclidean distance between two parallel hyperplane $\mathbf{w}^\top\mathbf{x} + b_1 = 0$ and $\mathbf{w}^\top\mathbf{x} + b_2 = 0$ is $\frac{|b_1 - b_2|}{||\mathbf{w}||_2}$ (Hint: you can use the result from the last question to help you prove this one).

\begin{soln}  According to question 1, since these two hyperplanes are parallel, every point P1 in plane 1 will have same smallest distance to plane 2 and this distance is also the smallest distance b/w two planes. So we can get the smallest distance as $\frac{|\mathbf{w}^\top\mathbf{P1} + b_2|}{\sqrt{|w|^2}}$. According to the equations of plane 1, we can get $\mathbf{w}^\top\mathbf{P1} = -b_1$. So we can write the distance as $\frac{|-b_1+ b_2|}{\sqrt{|w|^2}} =\frac{|b_1- b_2|}{\sqrt{|w|^2}} =\frac{|b_1- b_2|}{||\mathbf{w}||_2}  $
\end{soln}

\end{enumerate}


\section{Programming Skills [3 pts]}
Sampling from a distribution.  For each question, submit a scatter plot (you will have 5 plots in total).  Make sure the axes for all plots have the same ranges.
\begin{enumerate}
\item Draw 100 items $\mathbf{x} = [x_1, x_2]^\top$ from a
  2-dimensional Gaussian distribution $N(\mathbf{\mu}, \Sigma)$ with mean $\mathbf{\mu}=(0, 0)^T$ and
  identity covariance matrix $\Sigma=I$, i.e.,
  $p(\mathbf{x}) =
  \frac{1}{2\pi}\exp\left(-\frac{||\mathbf{x}||^2}{2}\right)$, and
  make a scatter plot ($x_1$ vs. $x_2$).  
  
	\begin{soln}
	    \begin{figure}[H]
	        \centering
	        \includegraphics[width=0.4\textwidth]{81.png}
	        \captionsetup{labelformat=empty}
	        \caption{}
	        \label{fig:my_label}
	    \end{figure}
	\end{soln}
\item Make a scatter plot by drawing 100 items from $N(\mathbf{\mu} + (1, -1)^\top, 2 \Sigma)$.

	\begin{soln}

	    \begin{figure}[H]
	        \centering
	        \includegraphics[width=0.4\textwidth]{82.png}
	        \captionsetup{labelformat=empty}
	        \caption{}
	        \label{fig:my_label}
	    \end{figure}
	\end{soln}
\item Make a scatter plot by drawing 100 items from a mixture distribution 
$0.3 N\left((1, 0)^\top, \begin{pmatrix} 1 & 0.2 \\ 0.2 & 1\\ \end{pmatrix}\right)
+0.7 N\left((-1, 0)^\top, \begin{pmatrix} 1 & -0.2 \\ -0.2 & 1\\ \end{pmatrix}\right)
$.

  	\begin{soln}

	   \begin{figure}[H]
	        \centering
	        \includegraphics[width=0.4\textwidth]{3.png}
	        \captionsetup{labelformat=empty}
	        \caption{}
	        \label{fig:my_label}
	   \end{figure}
	\end{soln}
\end{enumerate}


\bibliographystyle{apalike}


%----------------------------------------------------------------------------------------


\end{document}
